{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Palindroms"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "# This allows to download web pages\nimport requests\n\n# This is just a way for having a list of lines from a file on the web.\n# Let's remember that spark cannot process files from the web by itself.\n# This is done only as an example, it cannot be done with huge files.\n# Otherwise the machine may have hard times in processing it.\nfile_content_palindroms = requests.get('https://raw.githubusercontent.com/forons/BigDataExamples/master/files/data.txt').iter_lines()\n\n\ndef reverse(s):\n  rev = ''\n  for i in s: \n    rev = i + rev\n  return rev\n\nsc.parallelize(file_content_palindroms).filter(lambda x: x == reverse(x)).collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Words that occur exactly 5 times"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "# x[0] access the key, and x[1] access to the value of the pair/tuple\nword_count.filter(lambda x: x[1] == 5).collect()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Group by occurrences"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "result = word_count.groupBy(lambda x: x[1]).collect()\n\nseparator = '######'\n# Print a line for each element, separate elements with different occurrences with the separator variable\nfor key, val in result:\n  print(separator)\n  for elem in val:\n    print(elem, key)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Group Anagrams"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "def charsAndSort(x):\n  chars = list(x.lower())\n  chars.sort()\n  return (''.join(chars), [x])\n\nprint(file)\n\npartial = file.flatMap(lambda x: x.split(' ')).distinct()\\\n                                              .filter(lambda x: len(x) > 2)\\\n                                              .map(charsAndSort)\\\n                                              .reduceByKey(lambda x, y: x + y)\\\n                                              .filter(lambda x: len(x[1]) > 1)\n\npartial.collect()"
            ]
        }
    ],
    "metadata": {
        "name": "BigDataCourse - Spark 1 - Exercises",
        "notebookId": 2312768174863409
    },
    "nbformat": 4,
    "nbformat_minor": 0
}