{
    "cells": [
        {
            "cell_type": "code",
            "execution_count": 1,
            "metadata": {},
            "outputs": [],
            "source": [
                "my_range = spark.range(1000)\nprint(my_range.collect())\n\nnumbers = my_range.toDF(\"number\")\nprint(numbers.collect())"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": [
                "divis_by_2 = numbers.where(\"number % 2 = 0\")\ndivis_by_2.collect()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": [
                "divis_by_2.count()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [],
            "source": [
                "divis_by_2.printSchema()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### End-To-End Example"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": [
                "flight_data = spark.read.csv('/FileStore/tables/2015_summary-ebaee.csv', header='true')\nflight_data.take(3)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 7,
            "metadata": {},
            "outputs": [],
            "source": [
                "flight_data.toPandas()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 8,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql.types import StructField, StructType, StringType, LongType\n\nflight_schema = StructType([\n  StructField('DEST_COUNTRY_NAME', StringType(), True),\n  StructField('ORIGIN_COUNTRY_NAME', StringType(), True),\n  StructField('count', LongType(), False, metadata={\"descr\": \"data from some company\"})\n])\n\ndf = spark.read.format('csv').schema(flight_schema).load('/FileStore/tables/2015_summary-ebaee.csv')\ndf.show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql.functions import col, expr\n\nexpression = expr('(((count + 5) * 200) - 6) < 5000')\ndf.withColumn('new_column', expression).show()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": [
                "print(df.columns)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 11,
            "metadata": {},
            "outputs": [],
            "source": [
                "from pyspark.sql import Row\n\nimport my_row = Row(\"hi\", None, 12, False)\n\nprint(my_row[0])\nprint(my_row[1])\nprint(my_row[1:])\nprint(my_row[-1])"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [],
            "source": [
                "df.createOrReplaceTempView('df_table')"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": [
                "%sql\nSELECT * FROM df_table"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [],
            "source": [
                "query = \"\"\"\n  SELECT count * 10, ORIGIN_COUNTRY_NAME as origin FROM df_table\n  WHERE ORIGIN_COUNTRY_NAME <> 'Romania'\n\"\"\"\n\nspark.sql(query).show()\ndf.select('DEST_COUNTRY_NAME').show(2)"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 15,
            "metadata": {},
            "outputs": [],
            "source": [
                ""
            ]
        }
    ],
    "metadata": {
        "name": "BigDataCourse - Spark SQL",
        "notebookId": 4062513539100646
    },
    "nbformat": 4,
    "nbformat_minor": 0
}